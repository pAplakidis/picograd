A from-scratch toy implementation of neural networks, backpropagation, etc

TODO:
* Fix backward pass/gradient decent
* Implement optimization
* Tidy up code and use the operation wrappers for Tensor
* Implement convolution
* Implement maxpool and avgpool
* Implement BatchNorm1d and 2d
* Test on actual neural networks (full training and evaluation of simple models)

